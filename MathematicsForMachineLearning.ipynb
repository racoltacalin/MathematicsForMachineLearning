{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematics for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In general, vectors are special objects that can be added together and miltiplied by scalars to produce another object of the same king!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Geometric vectors\n",
    "#### 1.2. Polynomials are also vectors\n",
    "#### 1.3. Audio signals are vectors\n",
    "#### 1.4. Elements of R^n (tuples of n real numbers) are vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The concept of a vector space and its properties underline much of ***Machine Learning***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***INFO 1:* Gaussian elimination is an intuitive and constructive way to solve a system of linear equations with thousands of variables.**\n",
    "\n",
    "***INFO 2:* Groups play an important role in computer science.Besides providing a fundamental framework for operations on sets, they are heavily used in\n",
    "cryptography, coding theory, and graphics.**\n",
    "\n",
    "***INFO 3:* Vector subspaces are a key idea in machine learning.**\n",
    "\n",
    "***INFO 4:* Linear independence is one of the most important concepts in linear\n",
    "algebra.**\n",
    "\n",
    "***INFO 5:* In the machine learning literature, the distinction between linear and affine is sometimes not clear so that we can find references to affine spaces/mappings as linear spaces/mappings.**\n",
    "\n",
    "***INFO 6:* Symmetric, positive definite matrices play an important role in machine learning, and they are defined via the inner product. The idea of symmetric positive semidefinite matrices is key in the definition of kernels**\n",
    "\n",
    "***INFO 7:* Projections are an important class of linear transformations (besides rotations and reflections) and play an important role in graphics, coding theory, statistics and machine learning. In machine learning, we often deal with data that is high-dimensional. High-dimensional data is often hard to analyze or visualize. However, high-dimensional data quite often possesses the property that only a few dimensions contain most information, and most other dimensions are not essential to describe key properties of the data. When we compress or visualize high-dimensional data, we will lose information. To minimize this compression loss, we ideally find the most informative dimensions in the data.**\n",
    "\n",
    "***INFO 8:* In machine learning, inner products are important in the context of kernel methods.**\n",
    "\n",
    "***INFO 9:* Methods to analyze and learn from network data are an essential component of machine learning methods.**\n",
    "\n",
    "***INFO 10:* The Cholesky decomposition is an important tool for the numerical computations underlying machine learning.**\n",
    "\n",
    "***INFO 11:* The SVD is used in a variety of applications in machine learning from least-squares problems in curve fitting to solving systems of linear equations. Substituting a matrix with its SVD has often the advantage of making calculation more robust to numerical rounding errors. The SVD’s ability to approximate matrices with “simpler” matrices in a principled manner opens up machine learning applications ranging from dimensionality reduction and topic modeling to data compression and clustering.**\n",
    "\n",
    "***INFO 12:* The low-rank approximation of a matrix appears in many machine learning applications, e.g., image processing, noise filtering, and regularization of ill-posed problems.**\n",
    "\n",
    "***INFO 13:* Many algorithms in machine learning optimize an objective function with respect to a set of desired model parameters that control how well a model explains the data: Finding good parameters can be phrased as an optimization problem.**\n",
    "\n",
    "***INFO 14:* Vector calculus is one of the fundamental mathematical tools we need in machine learning.**\n",
    "\n",
    "***INFO 15:* To facilitate learning in machine learning models, we need to compute gradients of functions, since the gradient points in the direction of steepest ascent.**\n",
    "\n",
    "***INFO 16:* When we compute gradients and implement them, we can use finite differences to numerically test our computation and implementation: We choose the value 'h' to be small (e.g. h = 10^-4) and compare the finite-difference approximation with our -analytic- implementation of the gradient. If the error is small, our gradient implementation is probably correct.**\n",
    "\n",
    "***INFO 17:* The Jacobian determinant is important because we transform random variables and probability distributions. These transformations are extremely relevant in machine learning in the context of *training deep neural networks* using the\n",
    "reparametrization trick, also called infinite perturbation analysis.**\n",
    "\n",
    "***INFO 18:* In many machine learning applications, we find good model parameters by performing gradient descent which relies on the fact that we can compute the gradient of a learning objective with respect to the parameters of the model.**\n",
    "\n",
    "***INFO 19:* For training deep neural network models, the backpropagation algorithm (Kelley, 1960; Bryson, 1961; Dreyfus, 1962; Rumelhart et al., 1986) is an efficient way to compute the gradient of an error function with respect to the parameters of the model.**\n",
    "\n",
    "***INFO 20:* An area where the chain rule is used to an extreme is deep learning, where the function value y is computed as a many-level function composition.**\n",
    "\n",
    "***INFO 21:* **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
